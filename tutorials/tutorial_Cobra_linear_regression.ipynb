{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cobra's approach to linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cobra requires the usual Python packages for data science:\n",
    "\n",
    "- numpy (>=1.19.4)\n",
    "- pandas (>=1.1.5)\n",
    "- scipy (>=1.5.4)\n",
    "- scikit-learn (>=0.24.1)\n",
    "- matplotlib (>=3.3.3)\n",
    "- seaborn (>=0.11.0)\n",
    "\n",
    "These packages, along with their versions are listed in requirements.txt and can be installed using pip.\n",
    "\n",
    "If you want to install Cobra with e.g. pip, you don't have to install all of these requirements as these are automatically installed with Cobra itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to install Cobra is using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pythonpredictions-cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section we will walk you through all the required steps to build a predictive linear regression model using **Cobra**. All classes and functions used here are well-documented. In case you want more information on a class or function, run `help(function_or_class_you_want_info_from)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a good model involves three steps:\n",
    "\n",
    "1. **Preprocessing**: properly prepare the predictors (a synonym for “feature” or variable that we use throughout this tutorial) for modelling.\n",
    "\n",
    "2. **Feature Selection**: automatically select a subset of predictors which contribute most to the target variable or output in which you are interested.\n",
    "\n",
    "3. **Model Evaluation**: once a model has been build, a detailed evaluation can be performed by computing all sorts of evaluation metrics.\n",
    "\n",
    "Let's dive in!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miles Per Gallon Prediction\n",
    "\n",
    "- BASETABLE: seaborn dataset MPG.\n",
    "- GOAL: Predict the distance (measured in miles) that a car can travel per gallon of fuel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.preprocessing import PreProcessor\n",
    "\n",
    "from cobra.model_building import univariate_selection\n",
    "from cobra.model_building import ForwardFeatureSelection\n",
    "# from cobra.model_building import LinearRegressionModel\n",
    "\n",
    "from cobra.evaluation import RegressionEvaluator\n",
    "from cobra.evaluation import generate_pig_tables\n",
    "from cobra.evaluation import plot_univariate_predictor_quality\n",
    "from cobra.evaluation import plot_correlation_matrix\n",
    "from cobra.evaluation import plot_performance_curves\n",
    "from cobra.evaluation import plot_variable_importance\n",
    "from cobra.evaluation import plot_incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"mpg\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, we assume the data for model building is available in a pandas DataFrame. This DataFrame should contain a an ID column, a target column (e.g. “**mpg**”) and a number of candidate predictors (features) to build a model with.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is required to set all category vars to object dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.dtypes==\"category\"] = (df.select_dtypes([\"category\"]).apply(lambda x: x.astype(\"object\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first part focusses on preparing the predictors for modelling by:\n",
    "\n",
    "1. Defining the ID column, the target, discrete and contineous variables\n",
    "\n",
    "2. Splitting the dataset into training, selection and validation datasets.\n",
    "\n",
    "3. Binning continuous variables into discrete intervals\n",
    "\n",
    "4. Replacing missing values of both categorical and continuous variables (which are now binned) with an additional “Missing” bin/category\n",
    "\n",
    "5. Regrouping categories in new category “other”\n",
    "\n",
    "6. Replacing bins/categories with their corresponding average of the target values\n",
    "\n",
    "*Note to user*: as any good data scientist knows, you still need to deal in your data with irregularities, such as outliers or very skewed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy dataset, the index will serve as ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = df.index + 1\n",
    "id_col = \"id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is the \"MPG\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"mpg\"\n",
    "df[target_col].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out which variables are categorical (discrete) and which are continuous.\n",
    "\n",
    "Discrete variables are definitely those that contain strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtypes = df.dtypes\n",
    "discrete_vars = [col for col in col_dtypes[col_dtypes==object].index.tolist() if col not in [id_col, target_col]] \n",
    "print(discrete_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also check for numerical columns that only contain a few different values, thus to be interpreted as discrete, categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in discrete_vars and col not in [id_col, target_col]: # omit discrete because a string and target\n",
    "        if len(val_counts) > 1 and len(val_counts) <= 10: # the column contains less than 10 different values\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a look at the printed variables, it is clear that we have to include those in the list of discrete variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_vars.extend([\"cylinders\"])\n",
    "discrete_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining variables can be labeled continous predictors, without including the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars = list(set(df.columns)\n",
    "                       - set(discrete_vars) \n",
    "                       - set([id_col, target_col]))\n",
    "continuous_vars                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can prepare **Cobra's PreProcessor** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using all Cobra's default parameters for preprocessing for now\n",
    "preprocessor = PreProcessor.from_params(\n",
    "    model_type=\"regression\"\n",
    ")\n",
    "\n",
    "# These are all available options: help(PreProcessor.from_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train-selection-validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable = preprocessor.train_selection_validation_split(data=df,\n",
    "                                                          train_prop=0.6,\n",
    "                                                          selection_prop=0.2,\n",
    "                                                          validation_prop=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the preprocessor pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the preprocessor pipeline:\n",
    "preprocessor.fit(basetable[basetable[\"split\"]==\"train\"],\n",
    "                 continuous_vars=continuous_vars,\n",
    "                 discrete_vars=discrete_vars,\n",
    "                 target_column_name=target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline can now be performed on the basetable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable = preprocessor.transform(basetable,\n",
    "                                   continuous_vars=continuous_vars,\n",
    "                                   discrete_vars=discrete_vars)\n",
    "basetable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Insights Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can the create the so-called Predictor Insights Graphs (PIGs in short). These are graphs that represents the insights of the relationship between a single predictor and the target. More specifically, the predictor is binned into groups, and we represent group size in bars and group target mean in a colored line. Moreover, we have the option to force order of predictor values. First, we compute the output needed to plot the PIG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_list = [col for col in basetable.columns if col.endswith(\"_bin\") or col.endswith(\"_processed\")]\n",
    "pig_tables = generate_pig_tables(basetable[basetable[\"split\"]==\"selection\"],\n",
    "                                 id_column_name=id_col,\n",
    "                                 target_column_name=target_col,\n",
    "                                 preprocessed_predictors=predictor_list)\n",
    "pig_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can plot a PIG graph for each of the predictors in the basetable. For instance, for the variable \"acceleration\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_incidence(pig_tables, variable=\"acceleration\", model_type=\"regression\",\n",
    "               column_order = list(basetable[\"acceleration_bin\"].unique().sort_values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the predictors are properly prepared, we can start building a predictive model, which boils down to selecting the right predictors from the dataset to train a model on.\n",
    "\n",
    "As a dataset typically contains many predictors, **we first perform a univariate preselection** to rule out any predictor with little to no predictive power. \n",
    "\n",
    "Later, using the list of preselected features, we build a multiple regression model using **forward feature selection** to choose the right set of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous steps, these were the predictors, as preprocessed so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_predictors = [\n",
    "    col for col in basetable.columns\n",
    "    if col.endswith(\"_bin\") or col.endswith(\"_processed\")\n",
    "]\n",
    "sorted(preprocessed_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for feature selection, we use the target encoded version of each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_predictors = [col for col in basetable.columns.tolist() if \"_enc\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A univariate selection on the preprocessed predictors can be conducted. The thresholds for retaining a feature can be changed by the user, for instance both at 10 for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmse = univariate_selection.compute_univariate_preselection(\n",
    "    target_enc_train_data=basetable[basetable[\"split\"]==\"train\"],\n",
    "    target_enc_selection_data=basetable[basetable[\"split\"]==\"selection\"],\n",
    "    predictors=preprocessed_predictors,\n",
    "    target_column=target_col,\n",
    "    model_type=\"regression\",\n",
    "    preselect_rmse_threshold = 10, # max. RMSE for selection\n",
    "    preselect_overtrain_threshold = 10) # difference between RMSE on train and selection set\n",
    "\n",
    "plot_univariate_predictor_quality(df_rmse)\n",
    "\n",
    "# As the square root of a variance, RMSE can be interpreted as the standard deviation of \n",
    "# the unexplained variance, and has the useful property of being in the same units as the response variable. \n",
    "# Lower values of RMSE indicate better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute correlations between the preprocessed predictors and plot it using a correlation matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlations between preprocessed predictors:\n",
    "df_corr = (univariate_selection\n",
    "           .compute_correlations(basetable[basetable[\"split\"]==\"train\"],\n",
    "                                 preprocessed_predictors))\n",
    "print(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "plot_correlation_matrix(df_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a list of the selected predictors after the univariate selection, run the following call:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_predictors = univariate_selection.get_preselected_predictors(df_rmse)\n",
    "preselected_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an initial preselection on the predictors, we can start building the model itself using forward feature selection to choose the right set of predictors. Since we use target encoding on all our predictors, we will only consider models with positive coefficients (no sign flip should occur) as this makes the model more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_selection = ForwardFeatureSelection(model_type=\"regression\",\n",
    "                                            # model_name=\"linear-regression\",\n",
    "                                            max_predictors=30,\n",
    "                                            pos_only=True)\n",
    "\n",
    "# fit the forward feature selection on the train data\n",
    "# has optional parameters to force and/or exclude certain predictors (see docs)\n",
    "forward_selection.fit(basetable[basetable[\"split\"]==\"train\"],\n",
    "                      target_column_name=target_col,\n",
    "                      predictors=preselected_predictors)\n",
    "\n",
    "# compute model performance\n",
    "performances = (forward_selection\n",
    "                .compute_model_performances(basetable, target_column_name = target_col))\n",
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we have completed 7 steps till no further improvement can be observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance curves\n",
    "plot_performance_curves(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance curves (RMSE per model with a particular number of predictors in case of linear regression), a final model can then be chosen and the variables importance can be plotted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the number of steps that were completed before stopping, fill that in between the brackets\n",
    "model = forward_selection.get_model_from_step(5)\n",
    "final_predictors = model.predictors\n",
    "final_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_importance = model.compute_variable_importance(\n",
    "    basetable[basetable[\"split\"]==\"selection\"])\n",
    "plot_variable_importance(variable_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: variable importance is based on correlation of the predictor with the model scores (and not the true labels!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if wanted, we can convert the model to a dictionary to store it as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.serialize()\n",
    "\n",
    "model_path = os.path.join(\"output\", \"model.json\")\n",
    "with open(model_path, \"w\") as file:\n",
    "    json.dump(model_dict, file)\n",
    "\n",
    "# To reload the model again from a JSON file, run the following snippet:\n",
    "# with open(model_path, \"r\") as file:\n",
    "#     model_dict = json.load(file)\n",
    "# model = LinearRegressionModel()\n",
    "# model.deserialize(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have build and selected a final model, it is time to evaluate its predictions on the test set against various evaluation metrics. The used evaluation metrics are:\n",
    "\n",
    "1. Coefficient of Determination (R2)\n",
    "2. Mean Absolute Error (MAE)\n",
    "3. Mean Squared Error (MSE)\n",
    "4. Root Mean Squared Error (RMSE)\n",
    "\n",
    "Furthermore, plotting makes the evaluation of a linear regression model a lot easier. We will use a **prediction plot**, which presents predictions from the model against actual values and a **Q-Q plot** from the standardized prediction residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy array of True target labels and predicted scores\n",
    "y_true = basetable[basetable[\"split\"]==\"selection\"][target_col].values\n",
    "y_pred = model.score_model(basetable[basetable[\"split\"]==\"selection\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator()\n",
    "evaluator.fit(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.scalar_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_qq()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
