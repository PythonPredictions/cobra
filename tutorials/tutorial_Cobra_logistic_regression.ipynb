{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"C:/Users/samuel.borms/Desktop/code/cobra\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cobra's approach to logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cobra requires the usual Python packages for data science, such as numpy, pandas and scikit-learn. These packages, along with their versions are listed in requirements.txt and can be installed using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to install Cobra with e.g. pip, you don't have to install all of these requirements as these are automatically installed with Cobra itself. Hence, the easiest way to install Cobra is using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pythonpredictions-cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section we will walk you through all the required steps to build a predictive logistic regression model using **Cobra**. All classes and functions used here are well-documented. In case you want more information on a class or function, run `help(function_or_class_you_want_info_from)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a good model involves three steps:\n",
    "\n",
    "1. **Preprocessing**: properly prepare the predictors (a synonym for “feature” or variable that we use throughout this tutorial) for modelling.\n",
    "\n",
    "2. **Feature selection**: automatically select a subset of predictors which contribute most to the target variable or output in which you are interested.\n",
    "\n",
    "3. **Model evaluation**: once a model has been build, a detailed evaluation can be performed by computing all sorts of evaluation metrics.\n",
    "\n",
    "Let's dive in!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival prediction using Titanic data\n",
    "\n",
    "- BASETABLE: seaborn dataset Titanic.\n",
    "- GOAL: Predict if individual survives in Titanic sinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra import __version__\n",
    "\n",
    "from cobra.preprocessing import PreProcessor\n",
    "\n",
    "from cobra.model_building import univariate_selection\n",
    "from cobra.model_building import ForwardFeatureSelection\n",
    "# from cobra.model_building import LogisticRegressionModel\n",
    "\n",
    "from cobra.evaluation import ClassificationEvaluator\n",
    "from cobra.evaluation import generate_pig_tables\n",
    "from cobra.evaluation import plot_univariate_predictor_quality\n",
    "from cobra.evaluation import plot_correlation_matrix\n",
    "from cobra.evaluation import plot_performance_curves\n",
    "from cobra.evaluation import plot_variable_importance\n",
    "from cobra.evaluation import plot_incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of Cobra being used is 1.1.0.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The version of Cobra being used is {__version__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, we assume the data for model building is available in a pandas DataFrame. This DataFrame should contain an ID column, a target column (e.g. “**survived**”) and a number of candidate predictors (features) to build a model with.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived          int64\n",
       "pclass            int64\n",
       "sex              object\n",
       "age             float64\n",
       "sibsp             int64\n",
       "parch             int64\n",
       "fare            float64\n",
       "embarked         object\n",
       "class          category\n",
       "who              object\n",
       "adult_male         bool\n",
       "deck           category\n",
       "embark_town      object\n",
       "alive            object\n",
       "alone              bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is required to set all category vars to object dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.dtypes==\"category\"] = (df.select_dtypes([\"category\"]).apply(lambda x: x.astype(\"object\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first part focusses on preparing the predictors for modelling by:\n",
    "\n",
    "1. Defining the ID column, the target, discrete and contineous variables.\n",
    "\n",
    "2. Splitting the dataset into training, selection and validation datasets.\n",
    "\n",
    "3. Binning continuous variables into discrete intervals.\n",
    "\n",
    "4. Replacing missing values of both categorical and continuous variables (which are now binned) with an additional “Missing” bin/category.\n",
    "\n",
    "5. Regrouping categories in new category “other”.\n",
    "\n",
    "6. Replacing bins/categories with their corresponding incidence rate per category/bin.\n",
    "\n",
    "*Note to user*: as any good data scientist knows, you still need to deal in your data with irregularities, such as outliers or very skewed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy dataset, the index will serve as ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = df.index + 1\n",
    "id_col = \"id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is the \"survived\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove the columns \"who\" and \"adult_male\" since they are duplicate of \"sex\", and also \"alive\", which seems to be a duplicate of \"survived\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"who\", \"adult_male\", \"alive\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find out which variables are categorical (discrete) and which are continuous.\n",
    "\n",
    "Discrete variables are definitely those that contain strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'embarked', 'class', 'deck', 'embark_town']\n"
     ]
    }
   ],
   "source": [
    "col_dtypes = df.dtypes\n",
    "discrete_vars = [col for col in col_dtypes[col_dtypes==object].index.tolist() if col not in [id_col, target_col]] \n",
    "print(discrete_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also check for numerical columns that only contain a few different values, thus to be interpreted as discrete, categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pclass\n",
      "sibsp\n",
      "parch\n",
      "alone\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if col not in discrete_vars and col not in [id_col, target_col]: # omit discrete because a string and target\n",
    "        val_counts = df[col].nunique()\n",
    "        if val_counts > 1 and val_counts <= 10: # the column contains less than 10 different values\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a look at the printed variables, it is clear that we have to include those in the list of discrete variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'embarked',\n",
       " 'class',\n",
       " 'deck',\n",
       " 'embark_town',\n",
       " 'pclass',\n",
       " 'sibsp',\n",
       " 'parch',\n",
       " 'class',\n",
       " 'deck',\n",
       " 'alone']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_vars.extend([\"pclass\", \"sibsp\", \"parch\", \"class\", \"deck\", \"alone\"])\n",
    "discrete_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining variables can be labelled continous predictors, without including the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'fare']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_vars = list(set(df.columns)\n",
    "                       - set(discrete_vars) \n",
    "                       - set([id_col, target_col]))\n",
    "continuous_vars                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can prepare **Cobra's PreProcessor** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The target encoder's additive smoothing weight is set to 0. This disables smoothing and may make the encoding prone to overfitting. Increase the weight if needed.\n"
     ]
    }
   ],
   "source": [
    "# using all Cobra's default parameters for preprocessing here\n",
    "preprocessor = PreProcessor.from_params(\n",
    "    model_type=\"classification\"\n",
    ")\n",
    "\n",
    "# these are all available options: help(PreProcessor.from_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train-selection-validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1212)\n",
    "basetable = preprocessor.train_selection_validation_split(data=df,\n",
    "                                                          train_prop=0.6,\n",
    "                                                          selection_prop=0.25,\n",
    "                                                          validation_prop=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the preprocessor pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b036de6b894884986b1a3bcaf05ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing discretization bins...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d5b7033aa245b7add3a84a73292e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discretizing columns...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a56e1942f9e49fc9b2d13aee8e92514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting category regrouping...:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6006a204ed44dbb2070b208ea586af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fitting target encoding...:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor.fit(basetable[basetable[\"split\"]==\"train\"],\n",
    "                 continuous_vars=continuous_vars,\n",
    "                 discrete_vars=discrete_vars,\n",
    "                 target_column_name=target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline can now be performed on the basetable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b9156a86934b24ae6a2bdba4c7b5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Discretizing columns...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fdbe70161f4a61a12cb4e13e5d1e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying target encoding...:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>fare_bin</th>\n",
       "      <th>sex_processed</th>\n",
       "      <th>embarked_processed</th>\n",
       "      <th>class_processed</th>\n",
       "      <th>deck_processed</th>\n",
       "      <th>embark_town_processed</th>\n",
       "      <th>pclass_processed</th>\n",
       "      <th>sibsp_processed</th>\n",
       "      <th>parch_processed</th>\n",
       "      <th>alone_processed</th>\n",
       "      <th>sex_enc</th>\n",
       "      <th>embarked_enc</th>\n",
       "      <th>class_enc</th>\n",
       "      <th>deck_enc</th>\n",
       "      <th>embark_town_enc</th>\n",
       "      <th>pclass_enc</th>\n",
       "      <th>sibsp_enc</th>\n",
       "      <th>parch_enc</th>\n",
       "      <th>alone_enc</th>\n",
       "      <th>age_enc</th>\n",
       "      <th>fare_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>19.0 - 22.0</td>\n",
       "      <td>7.2 - 7.9</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.190883</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.311721</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.311721</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.354369</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>35.0 - 42.0</td>\n",
       "      <td>39.6 - 78.1</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "      <td>First</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.354369</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.566038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>selection</td>\n",
       "      <td>24.0 - 28.0</td>\n",
       "      <td>7.9 - 8.1</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.311721</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.311721</td>\n",
       "      <td>0.350543</td>\n",
       "      <td>0.354369</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>31.0 - 35.0</td>\n",
       "      <td>39.6 - 78.1</td>\n",
       "      <td>female</td>\n",
       "      <td>Other</td>\n",
       "      <td>First</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.354369</td>\n",
       "      <td>0.516746</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.566038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>31.0 - 35.0</td>\n",
       "      <td>7.9 - 8.1</td>\n",
       "      <td>male</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.190883</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.311721</td>\n",
       "      <td>0.300971</td>\n",
       "      <td>0.389513</td>\n",
       "      <td>0.311721</td>\n",
       "      <td>0.350543</td>\n",
       "      <td>0.354369</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class deck  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third  NaN   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First    C   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third  NaN   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First    C   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third  NaN   \n",
       "\n",
       "   embark_town  alone  id      split      age_bin     fare_bin sex_processed  \\\n",
       "0  Southampton  False   1      train  19.0 - 22.0    7.2 - 7.9          male   \n",
       "1    Cherbourg  False   2      train  35.0 - 42.0  39.6 - 78.1        female   \n",
       "2  Southampton   True   3  selection  24.0 - 28.0    7.9 - 8.1        female   \n",
       "3  Southampton  False   4      train  31.0 - 35.0  39.6 - 78.1        female   \n",
       "4  Southampton   True   5      train  31.0 - 35.0    7.9 - 8.1          male   \n",
       "\n",
       "  embarked_processed class_processed deck_processed embark_town_processed  \\\n",
       "0              Other           Other        Missing                 Other   \n",
       "1              Other           First          Other                 Other   \n",
       "2              Other           Other        Missing                 Other   \n",
       "3              Other           First          Other                 Other   \n",
       "4              Other           Other        Missing                 Other   \n",
       "\n",
       "  pclass_processed  sibsp_processed  parch_processed alone_processed  \\\n",
       "0            Other                1                0           False   \n",
       "1                1                1                0           False   \n",
       "2            Other                0                0            True   \n",
       "3                1                1                0           False   \n",
       "4            Other                0                0            True   \n",
       "\n",
       "    sex_enc  embarked_enc  class_enc  deck_enc  embark_town_enc  pclass_enc  \\\n",
       "0  0.190883      0.389513   0.311721  0.300971         0.389513    0.311721   \n",
       "1  0.772973      0.389513   0.629630  0.647887         0.389513    0.629630   \n",
       "2  0.772973      0.389513   0.311721  0.300971         0.389513    0.311721   \n",
       "3  0.772973      0.389513   0.629630  0.647887         0.389513    0.629630   \n",
       "4  0.190883      0.389513   0.311721  0.300971         0.389513    0.311721   \n",
       "\n",
       "   sibsp_enc  parch_enc  alone_enc   age_enc  fare_enc  \n",
       "0   0.540323   0.354369   0.516746  0.270833  0.232143  \n",
       "1   0.540323   0.354369   0.516746  0.357143  0.566038  \n",
       "2   0.350543   0.354369   0.311927  0.320000  0.222222  \n",
       "3   0.540323   0.354369   0.516746  0.536585  0.566038  \n",
       "4   0.350543   0.354369   0.311927  0.536585  0.222222  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable = preprocessor.transform(basetable,\n",
    "                                   continuous_vars=continuous_vars,\n",
    "                                   discrete_vars=discrete_vars)\n",
    "basetable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Insights Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can the create the so-called Predictor Insights Graphs (PIGs in short). These are graphs that represents the insights of the relationship between a single predictor and the target. More specifically, the predictor is binned into groups, and we represent group size in bars and group (target) incidence in a colored line. Moreover, we have the option to force order of predictor values. First, we compute the output needed to plot the PIG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>label</th>\n",
       "      <th>pop_size</th>\n",
       "      <th>global_avg_target</th>\n",
       "      <th>avg_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1.0 - 14.0</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>14.0 - 19.0</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>19.0 - 22.0</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>22.0 - 24.0</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>24.0 - 28.0</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>28.0 - 31.0</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>31.0 - 35.0</td>\n",
       "      <td>0.085586</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>35.0 - 42.0</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>age</td>\n",
       "      <td>42.0 - 51.0</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>age</td>\n",
       "      <td>51.0 - 80.0</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>age</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.198198</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alone</td>\n",
       "      <td>False</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.547368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alone</td>\n",
       "      <td>True</td>\n",
       "      <td>0.572072</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.299213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class</td>\n",
       "      <td>First</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deck</td>\n",
       "      <td>B</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deck</td>\n",
       "      <td>D</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deck</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.788288</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.331429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deck</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embark_town</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embark_town</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embarked</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embarked</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fare</td>\n",
       "      <td>0.0 - 7.2</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fare</td>\n",
       "      <td>7.2 - 7.9</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fare</td>\n",
       "      <td>7.9 - 8.1</td>\n",
       "      <td>0.085586</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fare</td>\n",
       "      <td>8.1 - 10.5</td>\n",
       "      <td>0.099099</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fare</td>\n",
       "      <td>10.5 - 14.5</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fare</td>\n",
       "      <td>14.5 - 21.1</td>\n",
       "      <td>0.072072</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fare</td>\n",
       "      <td>21.1 - 27.4</td>\n",
       "      <td>0.112613</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fare</td>\n",
       "      <td>27.4 - 39.6</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fare</td>\n",
       "      <td>39.6 - 78.1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fare</td>\n",
       "      <td>78.1 - 512.3</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parch</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.360248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parch</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>parch</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parch</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pclass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pclass</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>female</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.709302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>male</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.213235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671171</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.355705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252252</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>4</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>8</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable         label  pop_size  global_avg_target  avg_target\n",
       "0           age    1.0 - 14.0  0.099099           0.405405    0.727273\n",
       "1           age   14.0 - 19.0  0.103604           0.405405    0.347826\n",
       "2           age   19.0 - 22.0  0.063063           0.405405    0.357143\n",
       "3           age   22.0 - 24.0  0.040541           0.405405    0.555556\n",
       "4           age   24.0 - 28.0  0.099099           0.405405    0.409091\n",
       "5           age   28.0 - 31.0  0.067568           0.405405    0.400000\n",
       "6           age   31.0 - 35.0  0.085586           0.405405    0.368421\n",
       "7           age   35.0 - 42.0  0.121622           0.405405    0.481481\n",
       "8           age   42.0 - 51.0  0.099099           0.405405    0.318182\n",
       "9           age   51.0 - 80.0  0.022523           0.405405    0.200000\n",
       "10          age       Missing  0.198198           0.405405    0.295455\n",
       "0         alone         False  0.427928           0.405405    0.547368\n",
       "1         alone          True  0.572072           0.405405    0.299213\n",
       "0         class         First  0.216216           0.405405    0.666667\n",
       "1         class         Other  0.783784           0.405405    0.333333\n",
       "0          deck             B  0.040541           0.405405    0.777778\n",
       "1          deck             D  0.027027           0.405405    0.666667\n",
       "2          deck       Missing  0.788288           0.405405    0.331429\n",
       "3          deck         Other  0.144144           0.405405    0.656250\n",
       "0   embark_town       Missing  0.000000           0.405405         NaN\n",
       "1   embark_town         Other  1.000000           0.405405    0.405405\n",
       "0      embarked       Missing  0.000000           0.405405         NaN\n",
       "1      embarked         Other  1.000000           0.405405    0.405405\n",
       "0          fare     0.0 - 7.2  0.027027           0.405405    0.000000\n",
       "1          fare     7.2 - 7.9  0.189189           0.405405    0.285714\n",
       "2          fare     7.9 - 8.1  0.085586           0.405405    0.210526\n",
       "3          fare    8.1 - 10.5  0.099099           0.405405    0.227273\n",
       "4          fare   10.5 - 14.5  0.117117           0.405405    0.384615\n",
       "5          fare   14.5 - 21.1  0.072072           0.405405    0.562500\n",
       "6          fare   21.1 - 27.4  0.112613           0.405405    0.600000\n",
       "7          fare   27.4 - 39.6  0.081081           0.405405    0.333333\n",
       "8          fare   39.6 - 78.1  0.135135           0.405405    0.433333\n",
       "9          fare  78.1 - 512.3  0.081081           0.405405    0.888889\n",
       "0         parch             0  0.725225           0.405405    0.360248\n",
       "1         parch             1  0.162162           0.405405    0.583333\n",
       "2         parch             2  0.103604           0.405405    0.478261\n",
       "3         parch             4  0.004505           0.405405    0.000000\n",
       "4         parch             5  0.004505           0.405405    0.000000\n",
       "0        pclass             1  0.216216           0.405405    0.666667\n",
       "1        pclass         Other  0.783784           0.405405    0.333333\n",
       "0           sex        female  0.387387           0.405405    0.709302\n",
       "1           sex          male  0.612613           0.405405    0.213235\n",
       "0         sibsp             0  0.671171           0.405405    0.355705\n",
       "1         sibsp             1  0.252252           0.405405    0.607143\n",
       "2         sibsp             2  0.018018           0.405405    0.500000\n",
       "3         sibsp             3  0.009009           0.405405    0.500000\n",
       "4         sibsp             4  0.018018           0.405405    0.000000\n",
       "5         sibsp             5  0.009009           0.405405    0.000000\n",
       "6         sibsp             8  0.022523           0.405405    0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_list = [col for col in basetable.columns\n",
    "                  if col.endswith(\"_bin\") or col.endswith(\"_processed\")]\n",
    "pig_tables = generate_pig_tables(basetable[basetable[\"split\"]==\"selection\"],\n",
    "                                 id_column_name=id_col,\n",
    "                                 target_column_name=target_col,\n",
    "                                 preprocessed_predictors=predictor_list)\n",
    "pig_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can plot a PIG graph for each of the predictors in the basetable. For instance, for the variable age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_order = list(basetable[\"age_bin\"].unique().sort_values())\n",
    "plot_incidence(pig_tables, variable=\"age\", model_type=\"classification\", column_order=col_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the predictors are properly prepared, we can start building a predictive model, which boils down to selecting the right predictors from the dataset to train a model on.\n",
    "\n",
    "As a dataset typically contains many predictors, **we first perform a univariate preselection** to rule out any predictor with little to no predictive power. \n",
    "\n",
    "Later, using the list of preselected features, we build a logistic regression model using **forward feature selection** to choose the right set of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous steps, these were the predictors, as preprocessed so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_predictors = [\n",
    "    col for col in basetable.columns\n",
    "    if col.endswith(\"_bin\") or col.endswith(\"_processed\")]\n",
    "sorted(preprocessed_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for feature selection, we use the target encoded version of each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_predictors = [col for col in basetable.columns.tolist() if \"_enc\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A univariate selection on the preprocessed predictors is conducted. The thresholds for retaining a feature are now the default values but can be changed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auc = univariate_selection.compute_univariate_preselection(\n",
    "    target_enc_train_data=basetable[basetable[\"split\"]==\"train\"],\n",
    "    target_enc_selection_data=basetable[basetable[\"split\"]==\"selection\"],\n",
    "    predictors=preprocessed_predictors,\n",
    "    target_column=target_col,\n",
    "    preselect_auc_threshold=0.53,  # if auc_selection <= 0.53 exclude predictor\n",
    "    preselect_overtrain_threshold=0.05)  # if (auc_train - auc_selection) >= 0.05 --> overfitting!\n",
    "\n",
    "plot_univariate_predictor_quality(df_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute correlations between the preprocessed predictors and plot it using a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = (univariate_selection\n",
    "           .compute_correlations(basetable[basetable[\"split\"]==\"train\"],\n",
    "                                 preprocessed_predictors))\n",
    "plot_correlation_matrix(df_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a list of the selected predictors after the univariate selection, run the following call:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_predictors = univariate_selection.get_preselected_predictors(df_auc)\n",
    "preselected_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an initial preselection on the predictors, we can start building the model itself using forward feature selection to choose the right set of predictors. Since we use target encoding on all our predictors, we will only consider models with positive coefficients (no sign flip should occur) as this makes the model more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forward_selection = ForwardFeatureSelection(model_type=\"classification\",\n",
    "                                            # model_name=\"my-logistic-regression\",\n",
    "                                            max_predictors=30,\n",
    "                                            pos_only=True)\n",
    "\n",
    "# fit the forward feature selection on the train and selection data\n",
    "# there are optional parameters to force and/or exclude certain predictors (see docs)\n",
    "forward_selection.fit(basetable[basetable[\"split\"]!=\"validation\"],\n",
    "                      target_column_name=target_col,\n",
    "                      predictors=preselected_predictors)\n",
    "\n",
    "# compute model performance\n",
    "performances = (forward_selection\n",
    "                .compute_model_performances(basetable, target_column_name=target_col))\n",
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, model improvement gradually flattens when more variables are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance curves\n",
    "plot_performance_curves(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance curves (AUC per model with a particular number of predictors in case of logistic regression), a final model can then be chosen and the variable importance can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the optimal step based on visual inspection in the plot above (try to find a knee point in the selection curve)\n",
    "model = forward_selection.get_model_from_step(4)\n",
    "\n",
    "final_predictors = model.predictors\n",
    "final_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_importance = model.compute_variable_importance(\n",
    "    basetable[basetable[\"split\"]==\"selection\"]\n",
    ")\n",
    "plot_variable_importance(variable_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: variable importance is based on correlation of the predictor with the model scores (and not the true labels!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if wanted, we can convert the model to a dictionary to store it as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.serialize()\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    ## To save the model as a JSON file, run the following snippet\n",
    "    model_path = os.path.join(\"output\", \"model.json\")\n",
    "    with open(model_path, \"w\") as file:\n",
    "        json.dump(model_dict, file)\n",
    "\n",
    "    ## To reload the model again from a JSON file, run the following snippet\n",
    "    with open(model_path, \"r\") as file:\n",
    "        model_dict = json.load(file)\n",
    "    model = LogisticRegressionModel()\n",
    "    model.deserialize(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built and selected a final model, it is time to evaluate its predictions on the test set against various evaluation metrics. The used evaluation metrics are:\n",
    "\n",
    "1. Accuracy\n",
    "2. Area Under Curve (AUC)\n",
    "3. Precision\n",
    "4. Recall\n",
    "5. F1\n",
    "6. Matthews correlation coefficient\n",
    "7. Lift at given percentage\n",
    "\n",
    "Furthermore, we can evaluate the classification performance using a confusion matrix.\n",
    "\n",
    "Plotting makes the evaluation of a logistic regression model a lot easier. We will first use a **Receiver Operating Characteristic (ROC) curve**, which is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis). Next, we display the **Cumulative Gains curve**, **Cumulative Lift curve** and **Cumulative Response curve**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numpy array of True target labels and predicted scores\n",
    "y_true = basetable[basetable[\"split\"]==\"validation\"][target_col].values\n",
    "y_pred = model.score_model(basetable[basetable[\"split\"]==\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ClassificationEvaluator()\n",
    "evaluator.fit(y_true, y_pred)  # Automatically find the best cut-off probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.scalar_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_cumulative_gains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_lift_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator.plot_cumulative_response_curve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
