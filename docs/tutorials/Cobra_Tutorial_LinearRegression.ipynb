{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cobra requires the usual Python packages for data science:\n",
    "- numpy (>=1.19.4)\n",
    "- pandas (>=1.1.5)\n",
    "- scipy (>=1.5.4)\n",
    "- scikit-learn (>=0.23.1)\n",
    "- matplotlib (>=3.3.3)\n",
    "- seaborn (>=0.11.0)\n",
    "\n",
    "These packages, along with their versions are listed in requirements.txt and can be installed using pip.\n",
    "\n",
    "\n",
    "Note: if you want to install cobra with e.g. pip, you don't have to install all of these requirements as these are automatically installed with cobra itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to install cobra is using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U pythonpredictions-cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section we will walk you through all the required steps to build a predictive linear regression model using **Cobra**. All classes and functions used here are well-documented. In case you want more information on a class or function, run the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(function_or_class_you_want_info_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a good model involves three steps\n",
    "\n",
    "1. **Preprocessing**: properly prepare the predictors (a synonym for “feature” or variable that we use throughout this tutorial) for modelling.\n",
    "\n",
    "2. **Feature Selection**: automatically select a subset of predictors which contribute most to the target variable or output in which you are interested.\n",
    "\n",
    "3. **Model Evaluation**: once a model has been build, a detailed evaluation can be performed by computing all sorts of evaluation metrics.\n",
    "\n",
    "\n",
    "\n",
    "Let's dive in!!!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miles Per Gallon Prediction\n",
    "- GOAL : Predict the distance, measured in miles, that a car can travel per gallon of fuel\n",
    "- BASETABLE : seaborn dataset MPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "from cobra.preprocessing import PreProcessor\n",
    "from cobra.evaluation import generate_pig_tables, plot_incidence\n",
    "from cobra.evaluation import evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset('mpg')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, we assume the data for model building is available in a pandas DataFrame. This DataFrame should contain a an ID column, a target column (e.g. “**mpg**”) and a number of candidate predictors (features) to build a model with.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is required to set all category vars to object dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.dtypes == 'category'] =\\\n",
    "    df.select_dtypes(['category'])\\\n",
    "    .apply(lambda x: x.astype('object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first part focusses on preparing the predictors for modelling by:\n",
    "\n",
    "1. Defining the ID column, the target, discrete and contineous variables\n",
    "\n",
    "2. Splitting the dataset into training, selection and validation datasets.\n",
    "\n",
    "3. Binning continuous variables into discrete intervals\n",
    "\n",
    "4. Replacing missing values of both categorical and continuous variables (which are now binned) with an additional “Missing” bin/category\n",
    "\n",
    "5. Regrouping categories in new category “other”\n",
    "\n",
    "6. Replacing bins/categories with their corresponding average of the target values\n",
    "\n",
    "*Disclaimer*: Cobra's Preprocesser is valid only if the original data does not contain extreme irregularities, such as outliers or very skewed distributions. This should always be checked beforehand by its user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy dataset, the index will serve as ID,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = df.index + 1\n",
    "id_col = \"id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and MPG is the target,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"mpg\"\n",
    "df[target_col].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out which variables are categorical (\"discrete\") and which are continous:\n",
    "\n",
    "\n",
    " => discrete are definitely those that contain strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtypes = df.dtypes\n",
    "discrete_vars = [col for col in col_dtypes[col_dtypes==object].index.tolist() if col not in [id_col, target_col]] \n",
    "print(discrete_vars)\n",
    "print()\n",
    "for col in discrete_vars:\n",
    "    print(col)\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also check for numerical columns that only contain a few different values, thus to be interpreted as discrete, categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col not in discrete_vars and col not in [id_col, target_col]: # if we didn't mark it as discrete already because it was string typed, or also excluding it if it is the target:\n",
    "        val_counts = df[col].value_counts()\n",
    "        if len(val_counts) > 1 and len(val_counts) <= 10: # The column contains less than 10 different values. \n",
    "            print(col)\n",
    "            print(val_counts)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking a look at the printed variables, it is clear that we have to include those in the list of discrete variables. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_vars.extend([\"cylinders\"])\n",
    "discrete_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining variables can be labelled continous predictors, without including the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars = list(set(df.columns)\n",
    "                       - set(discrete_vars) \n",
    "                       - set([id_col, target_col]))\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can prepare **Cobra's Preprocessor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreProcessor.from_params(\n",
    "    model_type=\"regression\"\n",
    ")\n",
    "\n",
    "# These are the options though:\n",
    "help(PreProcessor.from_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data into train-selection-validation set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.preprocessing import PreProcessor\n",
    "basetable = preprocessor.train_selection_validation_split(\n",
    "                data=df,\n",
    "                train_prop=0.6,\n",
    "                selection_prop=0.2,\n",
    "                validation_prop=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fit the preprocessor pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the preprocessor pipeline:\n",
    "preprocessor.fit(basetable[basetable[\"split\"] == \"train\"],\n",
    "                 continuous_vars=continuous_vars,\n",
    "                 discrete_vars=discrete_vars,\n",
    "                 target_column_name=target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline can now be performed on the basetable!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable = preprocessor.transform(basetable,\n",
    "                                   continuous_vars=continuous_vars,\n",
    "                                   discrete_vars=discrete_vars)\n",
    "\n",
    "\n",
    "basetable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the predictors are properly prepared, we can start building a predictive model, which boils down to selecting the right predictors from the dataset to train a model on.\n",
    "As a dataset typically contains many predictors, **we first perform a univariate preselection** to rule out any predictor with little to no predictive power. Later, using the list of preselected features, we build a multiple regression model using **forward feature selection** to choose the right set of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous steps, these were the predictors, as preprocessed so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_predictors = [\n",
    "    col for col in basetable.columns\n",
    "    if col.endswith(\"_bin\") or col.endswith(\"_processed\")\n",
    "]\n",
    "sorted(preprocessed_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for feature selection, we use the target encoded version of each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_predictors = [col for col in basetable.columns.tolist()\n",
    "                           if '_enc' in col]\n",
    "sorted(preprocessed_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A univariate selection on the preprocessed predictors can be conducted. The thresholds for retaining a feature can be changed by the user, for instance both at 10 for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.model_building import univariate_selection\n",
    "\n",
    "\n",
    "df_rmse = univariate_selection.compute_univariate_preselection(\n",
    "    target_enc_train_data=basetable[basetable[\"split\"] == \"train\"],\n",
    "    target_enc_selection_data=basetable[basetable[\"split\"] == \"selection\"],\n",
    "    predictors=preprocessed_predictors,\n",
    "    target_column=target_col,\n",
    "    model_type=\"regression\",\n",
    "    preselect_rmse_threshold = 10, #RMSE maximum for selection\n",
    "    preselect_overtrain_threshold = 10) #difference between RMSE on train and selection set\n",
    "df_rmse\n",
    "\n",
    "#As the square root of a variance, RMSE can be interpreted as the standard deviation of \n",
    "# the unexplained variance, and has the useful property of being in the same units as the response variable. \n",
    "#Lower values of RMSE indicate better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this does not work yet for regression\n",
    "from cobra.evaluation import plot_univariate_predictor_quality\n",
    "\n",
    "# Plot df_rmse to get a horizontal barplot:\n",
    "plot_univariate_predictor_quality(df_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute correlations between the preprocessed predictors and plot it using a correlation matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.evaluation import plot_correlation_matrix\n",
    "\n",
    "# compute correlations between preprocessed predictors:\n",
    "df_corr = (univariate_selection\n",
    "           .compute_correlations(basetable[basetable[\"split\"] == \"train\"],\n",
    "                                 preprocessed_predictors))\n",
    "print(df_corr)\n",
    "\n",
    "# plot correlation matrix\n",
    "plot_correlation_matrix(df_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a list of the selected predictors after the univariate selection, run the following call:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_predictors = (univariate_selection\n",
    "                          .get_preselected_predictors(df_rmse))\n",
    "preselected_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an initial preselection on the predictors, we can start building the model itself using forward feature selection to choose the right set of predictors. Since we use target encoding on all our predictors, we will only consider models with positive coefficients (no sign flip should occur) as this makes the model more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance curves (AUC per model with a particular number of predictors in case of logistic regression), a final model can then be chosen and the variables importance can be plotted:\n",
    "Note: variable importance is based on correlation of the predictor with the model scores (and not the true labels!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.model_building import ForwardFeatureSelection\n",
    "\n",
    "forward_selection = ForwardFeatureSelection(model_type=\"regression\",\n",
    "                                            #model_name=\"linear-regression\",\n",
    "                                            max_predictors=30,\n",
    "                                            pos_only=True)\n",
    "\n",
    "# fit the forward feature selection on the train data\n",
    "# has optional parameters to force and/or exclude certain predictors (see docs)\n",
    "forward_selection.fit(basetable[basetable[\"split\"] == \"train\"],\n",
    "                      target_column_name = target_col,\n",
    "                      predictors = preselected_predictors)\n",
    "                      #forced_predictors: list = [],\n",
    "                      #excluded_predictors: list = [])\n",
    "\n",
    "# compute model performance\n",
    "performances = (forward_selection\n",
    "                .compute_model_performances(basetable, target_column_name = target_col))\n",
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we have completed 7 steps till no further improvement can be observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.evaluation import plot_performance_curves\n",
    "\n",
    "# plot performance curves\n",
    "plot_performance_curves(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance curves (AUC per model with a particular number of predictors in case of logistic regression), a final model can then be chosen and the variables importance can be plotted:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = forward_selection.get_model_from_step(3)\n",
    "final_predictors = model.predictors\n",
    "final_predictors\n",
    "from cobra.evaluation import plot_variable_importance\n",
    "variable_importance = model.compute_variable_importance(\n",
    "    basetable[basetable[\"split\"] == \"selection\"])\n",
    "plot_variable_importance(variable_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can again export the model to a dictionary to store it as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.serialize()\n",
    "\n",
    "model_path = os.path.join(\"output\", \"model.json\")\n",
    "with open(model_path, \"w\") as file:\n",
    "    json.dump(model_dict, file)\n",
    "\n",
    "# To reload the model again from a JSON file, run the following snippet:\n",
    "# from cobra.model_building import LinearRegressionModel\n",
    "# with open(model_path, \"r\") as file:\n",
    "#     model_dict = json.load(file)\n",
    "# model = LinearRegressionModel()\n",
    "# model.deserialize(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have build and selected a final model, it is time to evaluate its predictions on the test set against various evaluation metrics. The used evaluation metrics are:\n",
    "1. Coefficient of Determination: R2\n",
    "2. Mean Absolute Error: MAE\n",
    "3. Mean Squared Error: MSE\n",
    "4. Root Mean Squared Error: RMSE\n",
    "\n",
    "Furthermore, plotting makes the evaluation of a linear regression model a lot easier. We will use a **prediction plot**, which presents predictions from the model against actual values and a **Q-Q plot** from the standardized prediction residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cobra.evaluation import RegressionEvaluator\n",
    "# get numpy array of True target labels and predicted scores:\n",
    "y_true = basetable[basetable[\"split\"] == \"selection\"][target_col].values\n",
    "y_pred = model.score_model(basetable[basetable[\"split\"] == \"selection\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator()\n",
    "evaluator.fit(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.compute_scalar_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.compute_qq_residuals(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_predictions(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work yet!\n",
    "evaluator.plot_qq()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
